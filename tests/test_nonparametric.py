from os.path import dirname, join

import numpy as np
from numpy.testing import assert_array_almost_equal, assert_array_equal
import pandas as pd
import pytest

from sksurv.nonparametric import (
    CensoringDistributionEstimator,
    SurvivalFunctionEstimator,
    kaplan_meier_estimator,
    nelson_aalen_estimator,
)
from sksurv.testing import FixtureParameterFactory
from sksurv.util import Surv

CHANNING_FILE = join(dirname(__file__), 'data', 'channing.csv')
AIDS_CHILDREN_FILE = join(dirname(__file__), 'data', 'Lagakos_AIDS_children.csv')
AIDS_ADULTS_FILE = join(dirname(__file__), 'data', 'Lagakos_AIDS_adults.csv')


class SimpleDataKMCases(FixtureParameterFactory):
    @property
    def time(self):
        return [1, 2, 2, 3, 7, 6, 5, 5, 3, 9, 11, 13, 17, 13, 6, 23]

    @property
    def true_x(self):
        return np.array([1, 2, 3, 5, 6, 7, 9, 11, 13, 17, 23])

    def data_all_uncensored(self):
        time = self.time
        event = np.repeat(True, len(time))
        true_y = np.array([0.9375, 0.8125, 0.6875, 0.5625, 0.4375, 0.375, 0.3125, 0.25, 0.125, 0.0625, 0])
        km_var = np.array([0.00366211, 0.00952148, 0.01342773, 0.01538086, 0.01538086,
                           0.01464844, 0.01342773, 0.01171875, 0.00683594, 0.00366211, 0.])
        return time, event, self.true_x, true_y, km_var

    def data_all_censored(self):
        time = self.time
        event = np.repeat(False, len(time))
        true_x = self.true_x
        true_y = np.ones(true_x.shape[0])
        km_var = np.zeros(true_x.shape[0])
        return time, event, true_x, true_y, km_var

    def data_first_censored(self):
        time = self.time
        event = np.repeat(True, len(time))
        event[0] = False
        true_y = np.array([
            1, 0.866666666666667, 0.733333333333333, 0.6, 0.466666666666667, 0.4,
            0.333333333333333, 0.266666666666667, 0.133333333333333, 0.0666666666666667, 0,
        ])
        km_var = np.array([
            0., 0.0077037, 0.01303704, 0.016, 0.01659259,
            0.016, 0.01481481, 0.01303704, 0.0077037, 0.00414815, 0.
        ])

        return time, event, self.true_x, true_y, km_var

    def data_last_censored(self):
        time = self.time
        event = np.repeat(True, len(time))
        event[-1] = False
        true_y = np.array(
            [0.9375, 0.8125, 0.6875, 0.5625, 0.4375, 0.375, 0.3125, 0.25, 0.125, 0.0625, 0.0625]
        )
        km_var = np.array([
            0.00366211, 0.00952148, 0.01342773, 0.01538086, 0.01538086,
            0.01464844, 0.01342773, 0.01171875, 0.00683594, 0.00366211,
            0.00366211])
        return time, event, self.true_x, true_y, km_var

    def data_first_and_last_censored(self):
        time = self.time
        event = np.repeat(True, len(time))
        event[0] = False
        event[-1] = False
        true_y = np.array([
            1, 0.866666666666667, 0.733333333333333, 0.6, 0.466666666666667, 0.4,
            0.333333333333333, 0.266666666666667, 0.133333333333333, 0.0666666666666667, 0.0666666666666667,
        ])
        km_var = np.array([
            0., 0.0077037, 0.01303704, 0.016, 0.01659259,
            0.016, 0.01481481, 0.01303704, 0.0077037, 0.00414815,
            0.00414815])
        return time, event, self.true_x, true_y, km_var


class SimpleDataNACases(FixtureParameterFactory):
    @property
    def time(self):
        return [1, 2, 2, 3, 7, 6, 5, 5, 3, 9, 11, 13, 17, 13, 6, 23]

    @property
    def true_x(self):
        return np.array([1, 2, 3, 5, 6, 7, 9, 11, 13, 17, 23])

    def data_all_uncensored(self):
        time = self.time
        event = np.repeat(True, len(time))
        true_y = np.array([
            0.0625, 0.195833333333333, 0.349679487179487, 0.531497668997669, 0.753719891219891,
            0.896577034077034, 1.0632437007437, 1.2632437007437, 1.7632437007437, 2.2632437007437, 3.2632437007437,
        ])

        return time, event, self.true_x, true_y

    def data_first_censored(self):
        time = self.time
        event = np.repeat(True, len(time))
        event[0] = False
        true_y = np.array([
            0, 0.133333333333333, 0.287179487179487, 0.468997668997669, 0.691219891219891,
            0.834077034077034, 1.0007437007437, 1.2007437007437, 1.7007437007437, 2.2007437007437, 3.2007437007437,
        ])

        return time, event, self.true_x, true_y

    def data_last_censored(self):
        time = self.time
        event = np.repeat(True, len(time))
        event[-1] = False
        true_y = np.array([
            0.0625, 0.195833333333333, 0.349679487179487, 0.531497668997669, 0.753719891219891,
            0.896577034077034, 1.0632437007437, 1.2632437007437, 1.7632437007437, 2.2632437007437, 2.2632437007437,
        ])

        return time, event, self.true_x, true_y

    def data_first_and_last_censored(self):
        time = self.time
        event = np.repeat(True, len(time))
        event[0] = False
        event[-1] = False
        true_y = np.array([
            0, 0.133333333333333, 0.287179487179487, 0.468997668997669, 0.691219891219891, 0.834077034077034,
            1.0007437007437, 1.2007437007437, 1.7007437007437, 2.2007437007437, 2.2007437007437,
        ])

        return time, event, self.true_x, true_y


@pytest.fixture()
def make_channing():
    def _make_channing(sex):  # pylint: disable=unused-argument
        data = pd.read_csv(CHANNING_FILE).query("entry < exit and sex == @sex")
        time_enter_m = data.loc[:, "entry"].values
        time_exit_m = data.loc[:, "exit"].values
        event_m = data.loc[:, "cens"].values == 1
        return time_enter_m, time_exit_m, event_m
    return _make_channing


@pytest.fixture()
def channing_male_true_x():
    return np.array([
        751, 759, 777, 781, 782, 806, 817, 820, 821, 823, 830, 835, 836, 837, 843, 846, 847, 852, 853, 854, 856,
        863, 865, 866, 869, 871, 872, 875, 876, 878, 879, 883, 885, 886, 890, 891, 893, 894, 895, 898, 900, 906,
        907, 909, 911, 914, 915, 919, 921, 923, 925, 926, 927, 932, 936, 938, 940, 943, 945, 946, 948, 951, 953,
        955, 956, 957, 959, 960, 962, 964, 966, 967, 969, 970, 971, 972, 973, 977, 978, 981, 982, 983, 984, 985,
        988, 989, 993, 996, 998, 1001, 1002, 1005, 1006, 1007, 1009, 1010, 1012, 1013, 1015, 1016, 1018, 1020,
        1021, 1022, 1023, 1025, 1027, 1029, 1031, 1033, 1036, 1039, 1041, 1043, 1044, 1045, 1046, 1047, 1051, 1053,
        1055, 1058, 1059, 1060, 1063, 1064, 1070, 1073, 1080, 1085, 1093, 1094, 1106, 1107, 1118, 1128, 1139, 1153,
    ])


@pytest.fixture()
def channing_female_true_x():
    return np.array([
        733, 746, 748, 760, 762, 768, 769, 772, 775, 777, 783, 792, 794, 795, 796, 797, 798, 799, 802, 804, 805,
        807, 808, 809, 810, 811, 812, 813, 814, 815, 818, 819, 820, 821, 822, 823, 824, 825, 827, 828, 829, 830,
        831, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852,
        854, 855, 856, 857, 858, 859, 860, 861, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875,
        876, 877, 878, 881, 882, 883, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899,
        900, 901, 902, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921,
        922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 938, 939, 940, 941, 942, 943,
        944, 945, 946, 947, 948, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965,
        966, 967, 968, 969, 970, 971, 972, 973, 975, 976, 977, 978, 979, 981, 982, 983, 984, 985, 986, 987, 988,
        989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007,
        1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1026,
        1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044,
        1047, 1049, 1050, 1051, 1053, 1054, 1055, 1056, 1057, 1059, 1061, 1062, 1063, 1064, 1065, 1068, 1070, 1071,
        1072, 1073, 1074, 1080, 1083, 1084, 1085, 1086, 1088, 1089, 1091, 1093, 1096, 1097, 1102, 1105, 1109, 1114,
        1115, 1119, 1122, 1131, 1132, 1134, 1140, 1142, 1147, 1152, 1172, 1186, 1192, 1200, 1207,
    ])


@pytest.fixture()
def make_aids():
    def _make_aids(kind):
        if kind == 'children':
            f = AIDS_CHILDREN_FILE
        elif kind == 'adults':
            f = AIDS_ADULTS_FILE
        else:
            raise ValueError('unknown kind {!r}'.format(kind))
        data = pd.read_csv(f, comment="#")

        event = np.repeat(True, data.shape[0])
        time_enter = 8 - data["INF"]
        time_exit = data["DIAG"]
        return event, time_enter, time_exit
    return _make_aids


@pytest.fixture()
def truncated_failure_data():
    rnd = np.random.RandomState(2016)
    time_exit = rnd.uniform(1, 100, size=25)
    time_enter = time_exit + 1
    event = rnd.binomial(1, 0.6, size=25).astype(bool)
    return event, time_exit, time_enter


@pytest.fixture()
def whas500_true_x():
    return np.array([
        1, 2, 3, 4, 5, 6, 7, 10, 11, 14, 16, 17, 18, 19, 20, 22, 26, 31, 32, 33, 34, 37, 42, 46, 49, 52, 53, 55,
        57, 60, 61, 62, 64, 69, 76, 81, 83, 88, 91, 93, 95, 97, 100, 101, 108, 109, 113, 116, 117, 118, 129, 132,
        134, 135, 137, 140, 143, 145, 146, 151, 166, 169, 187, 192, 197, 200, 226, 233, 235, 259, 269, 274, 287,
        289, 295, 297, 312, 313, 321, 328, 343, 345, 354, 358, 359, 363, 368, 371, 373, 376, 382, 385, 386, 390,
        392, 397, 398, 399, 400, 403, 405, 406, 407, 408, 411, 412, 416, 418, 419, 421, 422, 424, 426, 427, 433,
        437, 440, 442, 445, 446, 449, 450, 451, 452, 457, 458, 459, 465, 466, 467, 473, 475, 478, 479, 480, 486,
        497, 506, 507, 510, 511, 516, 519, 521, 522, 523, 524, 529, 530, 532, 535, 537, 542, 544, 550, 551, 552,
        554, 559, 562, 568, 570, 573, 578, 587, 589, 606, 609, 612, 614, 626, 631, 632, 644, 646, 649, 654, 659,
        662, 670, 673, 675, 704, 714, 718, 725, 849, 865, 903, 905, 920, 936, 953, 1048, 1054, 1065, 1096, 1098,
        1102, 1103, 1105, 1106, 1107, 1108, 1109, 1114, 1117, 1121, 1123, 1125, 1126, 1136, 1140, 1150, 1151, 1152,
        1157, 1159, 1160, 1161, 1162, 1163, 1165, 1169, 1170, 1174, 1178, 1182, 1187, 1189, 1190, 1191, 1196, 1199,
        1200, 1203, 1207, 1211, 1217, 1223, 1224, 1231, 1232, 1233, 1234, 1235, 1244, 1245, 1248, 1251, 1253, 1256,
        1257, 1262, 1265, 1266, 1272, 1273, 1274, 1277, 1279, 1280, 1290, 1295, 1298, 1302, 1308, 1314, 1317, 1319,
        1320, 1325, 1329, 1332, 1333, 1336, 1338, 1346, 1347, 1353, 1359, 1363, 1365, 1366, 1374, 1377, 1378, 1381,
        1384, 1385, 1388, 1390, 1400, 1408, 1409, 1420, 1430, 1433, 1438, 1444, 1449, 1451, 1454, 1456, 1458, 1496,
        1506, 1527, 1536, 1548, 1553, 1576, 1577, 1579, 1624, 1627, 1671, 1831, 1836, 1847, 1854, 1858, 1863, 1880,
        1883, 1885, 1887, 1889, 1893, 1899, 1904, 1914, 1919, 1920, 1923, 1926, 1931, 1933, 1934, 1936, 1939, 1940,
        1941, 1942, 1954, 1955, 1964, 1969, 1976, 1977, 1979, 1993, 1994, 2006, 2009, 2025, 2032, 2048, 2057, 2061,
        2064, 2065, 2066, 2083, 2084, 2086, 2100, 2108, 2113, 2114, 2118, 2122, 2123, 2125, 2126, 2131, 2132, 2139,
        2145, 2146, 2151, 2152, 2156, 2160, 2166, 2168, 2172, 2173, 2175, 2178, 2190, 2192, 2350, 2353, 2358,
    ])


class TestKaplanMeier:

    @staticmethod
    @pytest.mark.parametrize("time,event,true_x,true_y,km_var", SimpleDataKMCases().get_cases())
    def test_simple(time, event, true_x, true_y, km_var):
        x, y = kaplan_meier_estimator(event, time)

        assert_array_equal(x, true_x)
        assert_array_almost_equal(y, true_y)

        x, y, var = kaplan_meier_estimator(event, time, with_variance=True)
        assert_array_equal(x, true_x)
        assert_array_almost_equal(y, true_y)
        assert_array_almost_equal(var, km_var)

        ys = Surv.from_arrays(event, time)
        est = SurvivalFunctionEstimator().fit(ys)
        assert_array_equal(est.unique_time_[1:], true_x)
        assert_array_almost_equal(est.prob_[1:], true_y)
        assert_array_almost_equal(est.var_est_[1:], km_var)
        prob, var = est.predict_proba(true_x, with_variance=True)
        assert_array_almost_equal(prob, true_y)
        assert_array_almost_equal(var, km_var)

    @staticmethod
    @pytest.mark.parametrize("time,event,true_x,true_y,km_var", SimpleDataKMCases().get_cases())
    def test_wrong_dtype(time, event, true_x, true_y, km_var):  # noqa: F821 undefined name
        ys = Surv.from_arrays(event, time)
        est = SurvivalFunctionEstimator().fit(ys)
        with pytest.raises(
            ValueError,
            match="dtype='numeric' is not compatible with arrays of bytes/strings"
        ):
            est.predict_proba(np.array(["should", "not", "work"]), with_variance=True)

        with pytest.raises(
            ValueError,
            match=r"Found array with dim 3\. SurvivalFunctionEstimator expected <= 2\."
        ):
            est.predict_proba(np.random.randn(10, 9, 5), with_variance=True)

    @staticmethod
    def test_truncated_enter_larger_exit_error(truncated_failure_data):
        with pytest.raises(ValueError, match="exit time must be larger start time for all samples"):
            kaplan_meier_estimator(*truncated_failure_data, with_variance=True)

    @staticmethod
    def test_whas500(make_whas500, whas500_true_x):
        whas500 = make_whas500(with_mean=False, with_std=False)
        time = whas500.y['lenfol']
        event = whas500.y['fstat']

        x, y = kaplan_meier_estimator(event, time)

        assert_array_equal(x.astype(int), whas500_true_x)

        true_y = np.array(
            [0.984, 0.968, 0.962, 0.958, 0.954, 0.944, 0.932, 0.926, 0.918, 0.914, 0.912, 0.908, 0.902, 0.896, 0.892,
             0.888, 0.886, 0.884, 0.88, 0.874, 0.872, 0.87, 0.868, 0.866, 0.864, 0.862, 0.86, 0.858, 0.854, 0.852, 0.85,
             0.848, 0.844, 0.84, 0.838, 0.836, 0.834, 0.832, 0.83, 0.828, 0.826, 0.824, 0.822, 0.82, 0.818, 0.816,
             0.814, 0.812, 0.81, 0.808, 0.806, 0.804, 0.802, 0.8, 0.798, 0.794, 0.792, 0.79, 0.788, 0.786, 0.784, 0.78,
             0.776, 0.774, 0.772, 0.77, 0.768, 0.766, 0.764, 0.76, 0.758, 0.756, 0.754, 0.752, 0.75, 0.746, 0.744,
             0.742, 0.74, 0.738, 0.736, 0.734, 0.732, 0.73, 0.726, 0.724, 0.724, 0.724, 0.724, 0.724, 0.721960563380282,
             0.719921126760564, 0.719921126760564, 0.719921126760564, 0.717864209255533, 0.715807291750503,
             0.715807291750503, 0.715807291750503, 0.715807291750503, 0.715807291750503, 0.713714287973455,
             0.711621284196407, 0.711621284196407, 0.711621284196407, 0.711621284196407, 0.711621284196407,
             0.711621284196407, 0.711621284196407, 0.709484283342964, 0.709484283342964, 0.70734082629359,
             0.70734082629359, 0.70734082629359, 0.70734082629359, 0.70734082629359, 0.70734082629359, 0.70734082629359,
             0.705150916614662, 0.705150916614662, 0.702926465773606, 0.702926465773606, 0.702926465773606,
             0.702926465773606, 0.702926465773606, 0.702926465773606, 0.702926465773606, 0.702926465773606,
             0.700621788836644, 0.700621788836644, 0.69830950570517, 0.695997222573696, 0.695997222573696,
             0.695997222573696, 0.693669472665422, 0.693669472665422, 0.693669472665422, 0.691325994717228,
             0.691325994717228, 0.691325994717228, 0.691325994717228, 0.691325994717228, 0.691325994717228,
             0.691325994717228, 0.691325994717228, 0.691325994717228, 0.691325994717228, 0.691325994717228,
             0.691325994717228, 0.688865759860583, 0.688865759860583, 0.686387825472596, 0.683900913061463,
             0.68141400065033, 0.68141400065033, 0.68141400065033, 0.68141400065033, 0.678871411095665,
             0.678871411095665, 0.676319262933651, 0.673767114771638, 0.673767114771638, 0.673767114771638,
             0.673767114771638, 0.673767114771638, 0.673767114771638, 0.673767114771638, 0.673767114771638,
             0.673767114771638, 0.671114488335529, 0.66846186189942, 0.66846186189942, 0.66846186189942,
             0.665788014451822, 0.663114167004225, 0.660440319556627, 0.657766472109029, 0.655092624661431,
             0.655092624661431, 0.655092624661431, 0.652396770238956, 0.649700915816481, 0.649700915816481,
             0.646993828667246, 0.644286741518011, 0.641579654368776, 0.641579654368776, 0.638861096511281,
             0.636142538653786, 0.633423980796291, 0.630705422938796, 0.627986865081301, 0.625268307223807,
             0.622549749366312, 0.619831191508817, 0.617112633651322, 0.614394075793827, 0.611675517936333,
             0.611675517936333, 0.611675517936333, 0.611675517936333, 0.611675517936333, 0.611675517936333,
             0.611675517936333, 0.611675517936333, 0.611675517936333, 0.611675517936333, 0.611675517936333,
             0.611675517936333, 0.611675517936333, 0.611675517936333, 0.611675517936333, 0.608734770253946,
             0.608734770253946, 0.608734770253946, 0.608734770253946, 0.605721231787343, 0.605721231787343,
             0.602692625628406, 0.602692625628406, 0.602692625628406, 0.602692625628406, 0.602692625628406,
             0.599601894214927, 0.599601894214927, 0.599601894214927, 0.596478967682557, 0.596478967682557,
             0.596478967682557, 0.596478967682557, 0.596478967682557, 0.596478967682557, 0.596478967682557,
             0.596478967682557, 0.596478967682557, 0.593183503772709, 0.593183503772709, 0.593183503772709,
             0.593183503772709, 0.589832184542355, 0.589832184542355, 0.589832184542355, 0.589832184542355,
             0.586422749949625, 0.582973204361686, 0.582973204361686, 0.582973204361686, 0.582973204361686,
             0.582973204361686, 0.582973204361686, 0.582973204361686, 0.582973204361686, 0.582973204361686,
             0.582973204361686, 0.582973204361686, 0.582973204361686, 0.582973204361686, 0.582973204361686,
             0.582973204361686, 0.582973204361686, 0.582973204361686, 0.579112454663926, 0.579112454663926,
             0.579112454663926, 0.579112454663926, 0.579112454663926, 0.579112454663926, 0.579112454663926,
             0.579112454663926, 0.575034197940941, 0.575034197940941, 0.575034197940941, 0.575034197940941,
             0.575034197940941, 0.575034197940941, 0.575034197940941, 0.575034197940941, 0.575034197940941,
             0.575034197940941, 0.575034197940941, 0.575034197940941, 0.570506369610697, 0.570506369610697,
             0.570506369610697, 0.570506369610697, 0.570506369610697, 0.561153806174456, 0.561153806174456,
             0.561153806174456, 0.561153806174456, 0.561153806174456, 0.561153806174456, 0.561153806174456,
             0.561153806174456, 0.561153806174456, 0.561153806174456, 0.561153806174456, 0.561153806174456,
             0.561153806174456, 0.561153806174456, 0.561153806174456, 0.561153806174456, 0.561153806174456,
             0.561153806174456, 0.561153806174456, 0.561153806174456, 0.555542268112711, 0.549930730050967,
             0.544319191989222, 0.538707653927478, 0.533096115865733, 0.527484577803989, 0.521873039742244,
             0.5162615016805, 0.510649963618755, 0.505038425557011, 0.499426887495266, 0.493815349433521,
             0.493815349433521, 0.493815349433521, 0.493815349433521, 0.493815349433521, 0.493815349433521,
             0.493815349433521, 0.493815349433521, 0.493815349433521, 0.493815349433521, 0.493815349433521,
             0.493815349433521, 0.493815349433521, 0.493815349433521, 0.493815349433521, 0.493815349433521,
             0.493815349433521, 0.493815349433521, 0.493815349433521, 0.486444971083767, 0.486444971083767,
             0.486444971083767, 0.486444971083767, 0.486444971083767, 0.486444971083767, 0.486444971083767,
             0.486444971083767, 0.486444971083767, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052, 0.477910848784052,
             0.477910848784052, 0.438084944718714, 0.438084944718714, 0.438084944718714, 0.438084944718714,
             0.438084944718714, 0.438084944718714, 0.438084944718714, 0.438084944718714, 0.438084944718714,
             0.292056629812476, 0.146028314906238, 0])

        assert_array_almost_equal(y, true_y)

    @staticmethod
    def test_var_whas500(make_whas500, whas500_true_x):
        whas500 = make_whas500(with_mean=False, with_std=False)
        time = whas500.y['lenfol']
        event = whas500.y['fstat']

        x, y, var = kaplan_meier_estimator(event, time, with_variance=True)

        true_var = np.array(
            [3.14880000e-05, 6.19520000e-05, 7.31120000e-05, 8.04720000e-05,
             8.77680000e-05, 1.05728000e-04, 1.26752000e-04, 1.37048000e-04,
             1.50552000e-04, 1.57208000e-04, 1.60512000e-04, 1.67072000e-04,
             1.76792000e-04, 1.86368000e-04, 1.92672000e-04, 1.98912000e-04,
             2.02008000e-04, 2.05088000e-04, 2.11200000e-04, 2.20248000e-04,
             2.23232000e-04, 2.26200000e-04, 2.29152000e-04, 2.32088000e-04,
             2.35008000e-04, 2.37912000e-04, 2.40800000e-04, 2.43672000e-04,
             2.49368000e-04, 2.52192000e-04, 2.55000000e-04, 2.57792000e-04,
             2.63328000e-04, 2.68800000e-04, 2.71512000e-04, 2.74208000e-04,
             2.76888000e-04, 2.79552000e-04, 2.82200000e-04, 2.84832000e-04,
             2.87448000e-04, 2.90048000e-04, 2.92632000e-04, 2.95200000e-04,
             2.97752000e-04, 3.00288000e-04, 3.02808000e-04, 3.05312000e-04,
             3.07800000e-04, 3.10272000e-04, 3.12728000e-04, 3.15168000e-04,
             3.17592000e-04, 3.20000000e-04, 3.22392000e-04, 3.27128000e-04,
             3.29472000e-04, 3.31800000e-04, 3.34112000e-04, 3.36408000e-04,
             3.38688000e-04, 3.43200000e-04, 3.47648000e-04, 3.49848000e-04,
             3.52032000e-04, 3.54200000e-04, 3.56352000e-04, 3.58488000e-04,
             3.60608000e-04, 3.64800000e-04, 3.66872000e-04, 3.68928000e-04,
             3.70968000e-04, 3.72992000e-04, 3.75000000e-04, 3.78968000e-04,
             3.80928000e-04, 3.82872000e-04, 3.84800000e-04, 3.86712000e-04,
             3.88608000e-04, 3.90488000e-04, 3.92352000e-04, 3.94200000e-04,
             3.97848000e-04, 3.99648000e-04, 3.99648000e-04, 3.99648000e-04,
             3.99648000e-04, 3.99648000e-04, 4.01547219e-04, 4.03429347e-04,
             4.03429347e-04, 4.03429347e-04, 4.05346151e-04, 4.07245365e-04,
             4.07245365e-04, 4.07245365e-04, 4.07245365e-04, 4.07245365e-04,
             4.09235151e-04, 4.11206282e-04, 4.11206282e-04, 4.11206282e-04,
             4.11206282e-04, 4.11206282e-04, 4.11206282e-04, 4.11206282e-04,
             4.13293342e-04, 4.13293342e-04, 4.15380401e-04, 4.15380401e-04,
             4.15380401e-04, 4.15380401e-04, 4.15380401e-04, 4.15380401e-04,
             4.15380401e-04, 4.17593224e-04, 4.17593224e-04, 4.19895295e-04,
             4.19895295e-04, 4.19895295e-04, 4.19895295e-04, 4.19895295e-04,
             4.19895295e-04, 4.19895295e-04, 4.19895295e-04, 4.22440518e-04,
             4.22440518e-04, 4.24985740e-04, 4.27504874e-04, 4.27504874e-04,
             4.27504874e-04, 4.30050389e-04, 4.30050389e-04, 4.30050389e-04,
             4.32622887e-04, 4.32622887e-04, 4.32622887e-04, 4.32622887e-04,
             4.32622887e-04, 4.32622887e-04, 4.32622887e-04, 4.32622887e-04,
             4.32622887e-04, 4.32622887e-04, 4.32622887e-04, 4.32622887e-04,
             4.35580415e-04, 4.35580415e-04, 4.38570451e-04, 4.41560486e-04,
             4.44517220e-04, 4.44517220e-04, 4.44517220e-04, 4.44517220e-04,
             4.47646755e-04, 4.47646755e-04, 4.50776290e-04, 4.53869505e-04,
             4.53869505e-04, 4.53869505e-04, 4.53869505e-04, 4.53869505e-04,
             4.53869505e-04, 4.53869505e-04, 4.53869505e-04, 4.53869505e-04,
             4.57311489e-04, 4.60712138e-04, 4.60712138e-04, 4.60712138e-04,
             4.64154675e-04, 4.67554759e-04, 4.70912389e-04, 4.74227567e-04,
             4.77500292e-04, 4.77500292e-04, 4.77500292e-04, 4.80816058e-04,
             4.84088182e-04, 4.84088182e-04, 4.87360304e-04, 4.90588166e-04,
             4.93771766e-04, 4.93771766e-04, 4.96955366e-04, 5.00094065e-04,
             5.03187863e-04, 5.06236761e-04, 5.09240757e-04, 5.12199853e-04,
             5.15114047e-04, 5.17983341e-04, 5.20807734e-04, 5.23587226e-04,
             5.26321817e-04, 5.26321817e-04, 5.26321817e-04, 5.26321817e-04,
             5.26321817e-04, 5.26321817e-04, 5.26321817e-04, 5.26321817e-04,
             5.26321817e-04, 5.26321817e-04, 5.26321817e-04, 5.26321817e-04,
             5.26321817e-04, 5.26321817e-04, 5.26321817e-04, 5.29879616e-04,
             5.29879616e-04, 5.29879616e-04, 5.29879616e-04, 5.33682725e-04,
             5.33682725e-04, 5.37485833e-04, 5.37485833e-04, 5.37485833e-04,
             5.37485833e-04, 5.37485833e-04, 5.41490926e-04, 5.41490926e-04,
             5.41490926e-04, 5.45566959e-04, 5.45566959e-04, 5.45566959e-04,
             5.45566959e-04, 5.45566959e-04, 5.45566959e-04, 5.45566959e-04,
             5.45566959e-04, 5.45566959e-04, 5.50355330e-04, 5.50355330e-04,
             5.50355330e-04, 5.50355330e-04, 5.55322079e-04, 5.55322079e-04,
             5.55322079e-04, 5.55322079e-04, 5.60477778e-04, 5.65732684e-04,
             5.65732684e-04, 5.65732684e-04, 5.65732684e-04, 5.65732684e-04,
             5.65732684e-04, 5.65732684e-04, 5.65732684e-04, 5.65732684e-04,
             5.65732684e-04, 5.65732684e-04, 5.65732684e-04, 5.65732684e-04,
             5.65732684e-04, 5.65732684e-04, 5.65732684e-04, 5.65732684e-04,
             5.73071024e-04, 5.73071024e-04, 5.73071024e-04, 5.73071024e-04,
             5.73071024e-04, 5.73071024e-04, 5.73071024e-04, 5.73071024e-04,
             5.81543072e-04, 5.81543072e-04, 5.81543072e-04, 5.81543072e-04,
             5.81543072e-04, 5.81543072e-04, 5.81543072e-04, 5.81543072e-04,
             5.81543072e-04, 5.81543072e-04, 5.81543072e-04, 5.81543072e-04,
             5.92760771e-04, 5.92760771e-04, 5.92760771e-04, 5.92760771e-04,
             5.92760771e-04, 6.16503544e-04, 6.16503544e-04, 6.16503544e-04,
             6.16503544e-04, 6.16503544e-04, 6.16503544e-04, 6.16503544e-04,
             6.16503544e-04, 6.16503544e-04, 6.16503544e-04, 6.16503544e-04,
             6.16503544e-04, 6.16503544e-04, 6.16503544e-04, 6.16503544e-04,
             6.16503544e-04, 6.16503544e-04, 6.16503544e-04, 6.16503544e-04,
             6.16503544e-04, 6.35409589e-04, 6.53809148e-04, 6.71702220e-04,
             6.89088806e-04, 7.05968906e-04, 7.22342519e-04, 7.38209645e-04,
             7.53570285e-04, 7.68424438e-04, 7.82772105e-04, 7.96613286e-04,
             8.09947980e-04, 8.09947980e-04, 8.09947980e-04, 8.09947980e-04,
             8.09947980e-04, 8.09947980e-04, 8.09947980e-04, 8.09947980e-04,
             8.09947980e-04, 8.09947980e-04, 8.09947980e-04, 8.09947980e-04,
             8.09947980e-04, 8.09947980e-04, 8.09947980e-04, 8.09947980e-04,
             8.09947980e-04, 8.09947980e-04, 8.09947980e-04, 8.39462551e-04,
             8.39462551e-04, 8.39462551e-04, 8.39462551e-04, 8.39462551e-04,
             8.39462551e-04, 8.39462551e-04, 8.39462551e-04, 8.39462551e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 8.81819603e-04,
             8.81819603e-04, 8.81819603e-04, 8.81819603e-04, 2.19490083e-03,
             2.19490083e-03, 2.19490083e-03, 2.19490083e-03, 2.19490083e-03,
             2.19490083e-03, 2.19490083e-03, 2.19490083e-03, 2.19490083e-03,
             1.51916907e-02, 1.44600570e-02, 0.00000000e+00])

        assert_array_almost_equal(var, true_var)

    @staticmethod
    def test_truncated_male(make_channing, channing_male_true_x):
        time_enter_m, time_exit_m, event_m = make_channing('Male')

        x, y, km_var = kaplan_meier_estimator(event_m, time_exit_m, time_enter_m, with_variance=True)

        assert_array_equal(x, channing_male_true_x)

        assert_array_equal(y[:3], np.array([1., 1., .5]))
        assert (y[3:] == 0).all()

        assert_array_equal(km_var[:3], np.array([0., 0., .125]))

    @staticmethod
    def test_truncated_male_older_68(make_channing, channing_male_true_x):
        time_enter_m, time_exit_m, event_m = make_channing('Male')

        x, y, km_var = kaplan_meier_estimator(event_m, time_exit_m, time_enter_m, time_min=68 * 12, with_variance=True)

        x_true = channing_male_true_x[6:]

        assert_array_equal(x, x_true)

        assert (y[:18] == 1).all()
        assert (km_var[:18] == 0).all()

        y_true = np.array([
            0.958333, 0.958333, 0.920000, 0.920000, 0.884615, 0.884615, 0.884615, 0.884615, 0.884615, 0.884615,
            0.884615, 0.884615, 0.858597, 0.833344, 0.833344, 0.808092, 0.808092, 0.808092, 0.784324, 0.761256,
            0.738187, 0.738187, 0.738187, 0.738187, 0.738187, 0.738187, 0.738187, 0.738187, 0.718236, 0.698285,
            0.698285, 0.698285, 0.698285, 0.698285, 0.678889, 0.678889, 0.659492, 0.659492, 0.659492, 0.659492,
            0.659492, 0.641173, 0.641173, 0.641173, 0.641173, 0.641173, 0.624300, 0.624300, 0.608692, 0.608692,
            0.593085, 0.593085, 0.593085, 0.593085, 0.593085, 0.593085, 0.593085, 0.577877, 0.577877, 0.563060,
            0.563060, 0.548623, 0.519748, 0.519748, 0.504898, 0.504898, 0.504898, 0.504898, 0.504898, 0.504898,
            0.488611, 0.488611, 0.458073, 0.458073, 0.458073, 0.458073, 0.458073, 0.458073, 0.458073, 0.441713,
            0.441713, 0.424724, 0.424724, 0.407735, 0.390746, 0.372139, 0.354418, 0.354418, 0.354418, 0.338308,
            0.321393, 0.321393, 0.321393, 0.321393, 0.321393, 0.303538, 0.285682, 0.285682, 0.266637, 0.247591,
            0.247591, 0.247591, 0.247591, 0.247591, 0.225083, 0.202575, 0.202575, 0.151931, 0.151931, 0.151931,
            0.151931, 0.101287, 0.050644, 0.050644,
        ])
        assert_array_almost_equal(y[18:], y_true)

        km_var_true = np.array([
            0.00166377, 0.00166377, 0.002944, 0.002944, 0.00392581,
            0.00392581, 0.00392581, 0.00392581, 0.00392581, 0.00392581,
            0.00392581, 0.00392581, 0.00435531, 0.00472183, 0.00472183,
            0.00505838, 0.00505838, 0.00505838, 0.00531348, 0.00552201,
            0.00570844, 0.00570844, 0.00570844, 0.00570844, 0.00570844,
            0.00570844, 0.00570844, 0.00570844, 0.00579133, 0.00586104,
            0.00586104, 0.00586104, 0.00586104, 0.00586104, 0.00590574,
            0.00590574, 0.00593858, 0.00593858, 0.00593858, 0.00593858,
            0.00593858, 0.00593951, 0.00593951, 0.00593951, 0.00593951,
            0.00593951, 0.00590822, 0.00590822, 0.00585401, 0.00585401,
            0.005795, 0.005795, 0.005795, 0.005795, 0.005795,
            0.005795, 0.005795, 0.00572696, 0.00572696, 0.00565096,
            0.00565096, 0.00556798, 0.00539224, 0.00539224, 0.00530273,
            0.00530273, 0.00530273, 0.00530273, 0.00530273, 0.00530273,
            0.00522285, 0.00522285, 0.00502754, 0.00502754, 0.00502754,
            0.00502754, 0.00502754, 0.00502754, 0.00502754, 0.00493292,
            0.00493292, 0.00483829, 0.00483829, 0.00473605, 0.0046262,
            0.00452583, 0.00440414, 0.00440414, 0.00440414, 0.00426059,
            0.00411701, 0.00411701, 0.00411701, 0.00411701, 0.00411701,
            0.00397337, 0.00381971, 0.00381971, 0.00366594, 0.00349776,
            0.00349776, 0.00349776, 0.00349776, 0.00349776, 0.00335128,
            0.0031705, 0.0031705, 0.0027452, 0.0027452, 0.0027452,
            0.0027452, 0.00292995, 0.00201488, 0.00201488])

        assert_array_almost_equal(km_var[18:], km_var_true)

    @staticmethod
    def test_truncated_female(make_channing, channing_female_true_x):
        time_enter_f, time_exit_f, event_f = make_channing('Female')

        x, y, km_var = kaplan_meier_estimator(event_f, time_exit_f, time_enter_f, with_variance=True)

        assert_array_equal(x, channing_female_true_x)

        assert (y[:19] == 1).all()
        assert (km_var[:19] == 0).all()

        y_true = np.array([
            0.952381, 0.952381, 0.952381, 0.952381, 0.952381, 0.952381, 0.952381, 0.952381, 0.952381, 0.952381,
            0.952381, 0.952381, 0.952381, 0.952381, 0.952381, 0.927318, 0.927318, 0.927318, 0.927318, 0.927318,
            0.927318, 0.927318, 0.907588, 0.907588, 0.907588, 0.907588, 0.907588, 0.907588, 0.907588, 0.907588,
            0.907588, 0.892710, 0.892710, 0.892710, 0.892710, 0.892710, 0.879386, 0.879386, 0.879386, 0.879386,
            0.879386, 0.879386, 0.879386, 0.879386, 0.879386, 0.879386, 0.879386, 0.879386, 0.879386, 0.879386,
            0.879386, 0.869930, 0.869930, 0.869930, 0.869930, 0.869930, 0.869930, 0.861317, 0.861317, 0.861317,
            0.861317, 0.861317, 0.853267, 0.853267, 0.853267, 0.853267, 0.853267, 0.853267, 0.853267, 0.853267,
            0.846097, 0.839161, 0.839161, 0.839161, 0.839161, 0.839161, 0.839161, 0.839161, 0.839161, 0.839161,
            0.839161, 0.833167, 0.833167, 0.827258, 0.827258, 0.827258, 0.827258, 0.821669, 0.821669, 0.821669,
            0.810786, 0.810786, 0.810786, 0.799829, 0.799829, 0.799829, 0.794532, 0.794532, 0.794532, 0.794532,
            0.789236, 0.789236, 0.789236, 0.789236, 0.784077, 0.784077, 0.784077, 0.784077, 0.779115, 0.779115,
            0.779115, 0.774275, 0.774275, 0.769375, 0.769375, 0.764536, 0.759697, 0.754858, 0.754858, 0.750199,
            0.750199, 0.745707, 0.745707, 0.745707, 0.741103, 0.736529, 0.736529, 0.736529, 0.727708, 0.727708,
            0.727708, 0.727708, 0.723298, 0.723298, 0.723298, 0.723298, 0.723298, 0.718805, 0.718805, 0.718805,
            0.718805, 0.718805, 0.714368, 0.714368, 0.714368, 0.714368, 0.709847, 0.709847, 0.709847, 0.705296,
            0.705296, 0.705296, 0.696589, 0.692235, 0.692235, 0.692235, 0.692235, 0.687854, 0.683473, 0.683473,
            0.679035, 0.679035, 0.679035, 0.670216, 0.665778, 0.665778, 0.665778, 0.661249, 0.661249, 0.661249,
            0.656657, 0.638028, 0.633405, 0.628815, 0.628815, 0.619567, 0.610180, 0.596099, 0.596099, 0.591330,
            0.586523, 0.581715, 0.576867, 0.576867, 0.572020, 0.567213, 0.562406, 0.552625, 0.552625, 0.552625,
            0.552625, 0.547646, 0.542528, 0.532095, 0.526878, 0.521610, 0.516287, 0.516287, 0.510852, 0.499983,
            0.489114, 0.483427, 0.477602, 0.477602, 0.465810, 0.459838, 0.459838, 0.454017, 0.454017, 0.448196,
            0.442299, 0.442299, 0.442299, 0.436069, 0.436069, 0.436069, 0.436069, 0.436069, 0.436069, 0.436069,
            0.410035, 0.390815, 0.390815, 0.384301, 0.377675, 0.370931, 0.370931, 0.370931, 0.370931, 0.370931,
            0.370931, 0.370931, 0.355476, 0.355476, 0.355476, 0.355476, 0.355476, 0.347012, 0.338337, 0.338337,
            0.320530, 0.311867, 0.311867, 0.302956, 0.294046, 0.284857, 0.284857, 0.275362, 0.265866, 0.246876,
            0.237001, 0.237001, 0.226696, 0.226696, 0.215901, 0.215901, 0.205620, 0.205620, 0.205620, 0.205620,
            0.205620, 0.191912, 0.191912, 0.177150, 0.162387, 0.147625, 0.147625, 0.147625, 0.132862, 0.132862,
            0.116255, 0.099647, 0.099647, 0.074735, 0.024912, 0.024912,
        ])
        assert_array_almost_equal(y[19:], y_true)

        km_var_true = np.array([
            0.00215959, 0.00215959, 0.00215959, 0.00215959, 0.00215959,
            0.00215959, 0.00215959, 0.00215959, 0.00215959, 0.00215959,
            0.00215959, 0.00215959, 0.00215959, 0.00215959, 0.00215959,
            0.00265903, 0.00265903, 0.00265903, 0.00265903, 0.00265903,
            0.00265903, 0.00265903, 0.00292808, 0.00292808, 0.00292808,
            0.00292808, 0.00292808, 0.00292808, 0.00292808, 0.00292808,
            0.00292808, 0.00305061, 0.00305061, 0.00305061, 0.00305061,
            0.00305061, 0.00313511, 0.00313511, 0.00313511, 0.00313511,
            0.00313511, 0.00313511, 0.00313511, 0.00313511, 0.00313511,
            0.00313511, 0.00313511, 0.00313511, 0.00313511, 0.00313511,
            0.00313511, 0.0031565, 0.0031565, 0.0031565, 0.0031565,
            0.0031565, 0.0031565, 0.00316775, 0.00316775, 0.00316775,
            0.00316775, 0.00316775, 0.00317301, 0.00317301, 0.00317301,
            0.00317301, 0.00317301, 0.00317301, 0.00317301, 0.00317301,
            0.00317089, 0.00316682, 0.00316682, 0.00316682, 0.00316682,
            0.00316682, 0.00316682, 0.00316682, 0.00316682, 0.00316682,
            0.00316682, 0.00315742, 0.00315742, 0.00314746, 0.00314746,
            0.00314746, 0.00314746, 0.0031361, 0.0031361, 0.0031361,
            0.00311201, 0.00311201, 0.00311201, 0.00308768, 0.00308768,
            0.00308768, 0.00307479, 0.00307479, 0.00307479, 0.00307479,
            0.0030618, 0.0030618, 0.0030618, 0.0030618, 0.00304834,
            0.00304834, 0.00304834, 0.00304834, 0.00303435, 0.00303435,
            0.00303435, 0.00302005, 0.00302005, 0.0030058, 0.0030058,
            0.00299138, 0.0029769, 0.00296236, 0.00296236, 0.00294748,
            0.00294748, 0.00293235, 0.00293235, 0.00293235, 0.00291731,
            0.00290221, 0.00290221, 0.00290221, 0.00287155, 0.00287155,
            0.00287155, 0.00287155, 0.00285618, 0.00285618, 0.00285618,
            0.00285618, 0.00285618, 0.00284087, 0.00284087, 0.00284087,
            0.00284087, 0.00284087, 0.00282547, 0.00282547, 0.00282547,
            0.00282547, 0.00281013, 0.00281013, 0.00281013, 0.00279479,
            0.00279479, 0.00279479, 0.00276365, 0.00274805, 0.00274805,
            0.00274805, 0.00274805, 0.00273245, 0.00271682, 0.00271682,
            0.00270122, 0.00270122, 0.00270122, 0.0026699, 0.00265422,
            0.00265422, 0.00265422, 0.0026386, 0.0026386, 0.0026386,
            0.00262302, 0.00256061, 0.00254485, 0.00252902, 0.00252902,
            0.00249731, 0.0024656, 0.00241768, 0.00241768, 0.00240171,
            0.00238575, 0.00236972, 0.00235369, 0.00235369, 0.0023376,
            0.00232139, 0.00230512, 0.00227264, 0.00227264, 0.00227264,
            0.00227264, 0.00225644, 0.00224041, 0.00220845, 0.00219231,
            0.00217616, 0.00216002, 0.00216002, 0.00214401, 0.00211156,
            0.00207853, 0.00206245, 0.00204656, 0.00204656, 0.00201456,
            0.00199845, 0.00199845, 0.00198162, 0.00198162, 0.00196459,
            0.00194755, 0.00194755, 0.00194755, 0.00193133, 0.00193133,
            0.00193133, 0.00193133, 0.00193133, 0.00193133, 0.00193133,
            0.00186694, 0.00181338, 0.00181338, 0.00179516, 0.00177694,
            0.00175871, 0.00175871, 0.00175871, 0.00175871, 0.00175871,
            0.00175871, 0.00175871, 0.00172967, 0.00172967, 0.00172967,
            0.00172967, 0.00172967, 0.00171821, 0.00170675, 0.00170675,
            0.00168203, 0.00166535, 0.00166535, 0.00164868, 0.00163018,
            0.00161169, 0.00161169, 0.00159319, 0.00157226, 0.00152311,
            0.00149731, 0.00149731, 0.00147151, 0.00147151, 0.00144568,
            0.00144568, 0.00141194, 0.00141194, 0.00141194, 0.00141194,
            0.00141194, 0.00140534, 0.00140534, 0.00139862, 0.001375,
            0.00133448, 0.00133448, 0.00133448, 0.00127707, 0.00127707,
            0.0012191, 0.00113208, 0.00113208, 0.00110224, 0.0005362,
            0.0005362
        ])
        assert_array_almost_equal(km_var[19:], km_var_true)

    @staticmethod
    def test_truncated_female_older_68(make_channing, channing_female_true_x):
        time_enter_f, time_exit_f, event_f = make_channing('Female')

        x, y, km_var = kaplan_meier_estimator(event_f, time_exit_f, time_enter_f, time_min=68 * 12, with_variance=True)

        x_true = channing_female_true_x[30:]
        assert_array_equal(x, x_true)

        y_true = np.array([
            1, 1, 1, 1, 0.973684, 0.973684, 0.973684, 0.973684, 0.973684, 0.973684, 0.973684, 0.952968, 0.952968,
            0.952968, 0.952968, 0.952968, 0.952968, 0.952968, 0.952968, 0.952968, 0.937345, 0.937345, 0.937345,
            0.937345, 0.937345, 0.923355, 0.923355, 0.923355, 0.923355, 0.923355, 0.923355, 0.923355, 0.923355,
            0.923355, 0.923355, 0.923355, 0.923355, 0.923355, 0.923355, 0.923355, 0.913426, 0.913426, 0.913426,
            0.913426, 0.913426, 0.913426, 0.904383, 0.904383, 0.904383, 0.904383, 0.904383, 0.895930, 0.895930,
            0.895930, 0.895930, 0.895930, 0.895930, 0.895930, 0.895930, 0.888402, 0.881120, 0.881120, 0.881120,
            0.881120, 0.881120, 0.881120, 0.881120, 0.881120, 0.881120, 0.881120, 0.874826, 0.874826, 0.868621,
            0.868621, 0.868621, 0.868621, 0.862752, 0.862752, 0.862752, 0.851325, 0.851325, 0.851325, 0.839821,
            0.839821, 0.839821, 0.834259, 0.834259, 0.834259, 0.834259, 0.828697, 0.828697, 0.828697, 0.828697,
            0.823281, 0.823281, 0.823281, 0.823281, 0.818070, 0.818070, 0.818070, 0.812989, 0.812989, 0.807844,
            0.807844, 0.802763, 0.797682, 0.792601, 0.792601, 0.787709, 0.787709, 0.782992, 0.782992, 0.782992,
            0.778159, 0.773355, 0.773355, 0.773355, 0.764093, 0.764093, 0.764093, 0.764093, 0.759463, 0.759463,
            0.759463, 0.759463, 0.759463, 0.754745, 0.754745, 0.754745, 0.754745, 0.754745, 0.750086, 0.750086,
            0.750086, 0.750086, 0.745339, 0.745339, 0.745339, 0.740561, 0.740561, 0.740561, 0.731419, 0.726847,
            0.726847, 0.726847, 0.726847, 0.722247, 0.717647, 0.717647, 0.712987, 0.712987, 0.712987, 0.703727,
            0.699067, 0.699067, 0.699067, 0.694311, 0.694311, 0.694311, 0.689489, 0.669929, 0.665075, 0.660255,
            0.660255, 0.650546, 0.640689, 0.625904, 0.625904, 0.620897, 0.615849, 0.610801, 0.605711, 0.605711,
            0.600621, 0.595574, 0.590526, 0.580256, 0.580256, 0.580256, 0.580256, 0.575029, 0.569655, 0.558700,
            0.553222, 0.547690, 0.542101, 0.542101, 0.536395, 0.524982, 0.513570, 0.507598, 0.501482, 0.501482,
            0.489100, 0.482830, 0.482830, 0.476718, 0.476718, 0.470606, 0.464414, 0.464414, 0.464414, 0.457873,
            0.457873, 0.457873, 0.457873, 0.457873, 0.457873, 0.457873, 0.430537, 0.410356, 0.410356, 0.403516,
            0.396559, 0.389478, 0.389478, 0.389478, 0.389478, 0.389478, 0.389478, 0.389478, 0.373250, 0.373250,
            0.373250, 0.373250, 0.373250, 0.364363, 0.355254, 0.355254, 0.336556, 0.327460, 0.327460, 0.318104,
            0.308748, 0.299100, 0.299100, 0.289130, 0.279160, 0.259220, 0.248851, 0.248851, 0.238031, 0.238031,
            0.226696, 0.226696, 0.215901, 0.215901, 0.215901, 0.215901, 0.215901, 0.201508, 0.201508, 0.186007,
            0.170507, 0.155006, 0.155006, 0.155006, 0.139506, 0.139506, 0.122067, 0.104629, 0.104629, 0.078472,
            0.026157, 0.026157,
        ])
        assert_array_almost_equal(y, y_true)

        km_var_true = np.array([
            0., 0., 0., 0., 0.0006743,
            0.0006743, 0.0006743, 0.0006743, 0.0006743, 0.0006743,
            0.0006743, 0.00106596, 0.00106596, 0.00106596, 0.00106596,
            0.00106596, 0.00106596, 0.00106596, 0.00106596, 0.00106596,
            0.00127135, 0.00127135, 0.00127135, 0.00127135, 0.00127135,
            0.00142649, 0.00142649, 0.00142649, 0.00142649, 0.00142649,
            0.00142649, 0.00142649, 0.00142649, 0.00142649, 0.00142649,
            0.00142649, 0.00142649, 0.00142649, 0.00142649, 0.00142649,
            0.0014935, 0.0014935, 0.0014935, 0.0014935, 0.0014935,
            0.0014935, 0.00154505, 0.00154505, 0.00154505, 0.00154505,
            0.00154505, 0.00158708, 0.00158708, 0.00158708, 0.00158708,
            0.00158708, 0.00158708, 0.00158708, 0.00158708, 0.00161672,
            0.00164292, 0.00164292, 0.00164292, 0.00164292, 0.00164292,
            0.00164292, 0.00164292, 0.00164292, 0.00164292, 0.00164292,
            0.00165886, 0.00165886, 0.00167364, 0.00167364, 0.00167364,
            0.00167364, 0.00168531, 0.00168531, 0.00168531, 0.00170539,
            0.00170539, 0.00170539, 0.00172489, 0.00172489, 0.00172489,
            0.00173284, 0.00173284, 0.00173284, 0.00173284, 0.00174054,
            0.00174054, 0.00174054, 0.00174054, 0.00174701, 0.00174701,
            0.00174701, 0.00174701, 0.00175194, 0.00175194, 0.00175194,
            0.00175591, 0.00175591, 0.00176006, 0.00176006, 0.00176364,
            0.00176704, 0.00177025, 0.00177025, 0.00177225, 0.00177225,
            0.00177321, 0.00177321, 0.00177321, 0.0017746, 0.00177569,
            0.00177569, 0.00177569, 0.00177579, 0.00177579, 0.00177579,
            0.00177579, 0.00177564, 0.00177564, 0.00177564, 0.00177564,
            0.00177564, 0.00177577, 0.00177577, 0.00177577, 0.00177577,
            0.00177577, 0.00177548, 0.00177548, 0.00177548, 0.00177548,
            0.00177548, 0.00177548, 0.00177548, 0.00177547, 0.00177547,
            0.00177547, 0.00177318, 0.00177185, 0.00177185, 0.00177185,
            0.00177185, 0.00177052, 0.00176907, 0.00176907, 0.00176774,
            0.00176774, 0.00176774, 0.00176444, 0.00176272, 0.00176272,
            0.00176272, 0.00176128, 0.00176128, 0.00176128, 0.00175999,
            0.00175448, 0.00175254, 0.0017503, 0.0017503, 0.00174564,
            0.00174098, 0.00173274, 0.00173274, 0.00173, 0.00172726,
            0.00172433, 0.00172141, 0.00172141, 0.00171829, 0.00171479,
            0.00171111, 0.00170393, 0.00170393, 0.00170393, 0.00170393,
            0.00170045, 0.00169742, 0.00169162, 0.00168832, 0.00168502,
            0.00168172, 0.00168172, 0.00167872, 0.00167179, 0.0016636,
            0.00166038, 0.00165756, 0.00165756, 0.00165149, 0.00164823,
            0.00164823, 0.00164365, 0.00164365, 0.00163865, 0.00163365,
            0.00163365, 0.00163365, 0.00163013, 0.00163013, 0.00163013,
            0.00163013, 0.00163013, 0.00163013, 0.00163013, 0.00161696,
            0.00159832, 0.00159832, 0.00159148, 0.00158465, 0.00157781,
            0.00157781, 0.00157781, 0.00157781, 0.00157781, 0.00157781,
            0.00157781, 0.00157525, 0.00157525, 0.00157525, 0.00157525,
            0.00157525, 0.00157823, 0.00158121, 0.00158121, 0.00158474,
            0.00158074, 0.00158074, 0.00157674, 0.00157031, 0.00156388,
            0.00156388, 0.00155745, 0.00154787, 0.00151924, 0.00150334,
            0.00150334, 0.00148743, 0.00148743, 0.00147151, 0.00147151,
            0.00144568, 0.00144568, 0.00144568, 0.00144568, 0.00144568,
            0.00145271, 0.00145271, 0.0014596, 0.00144672, 0.00141406,
            0.00141406, 0.00141406, 0.00136163, 0.00136163, 0.00130858,
            0.00122205, 0.00122205, 0.00120056, 0.00058953, 0.00058953
        ])
        assert_array_almost_equal(km_var, km_var_true)

    @staticmethod
    def test_right_truncated_children(make_aids):
        event, time_enter, time_exit = make_aids('children')

        x, y, km_var = kaplan_meier_estimator(event, -time_exit.values, -time_enter.values, with_variance=True)
        true_x = np.array([
            0.25, 0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 3.75, 4.00, 4.25, 4.50,
            5, 5.25, 5.50, 5.75, 6.50, 7,
        ])

        true_y = np.array([
            0, 0.02, 0.09, 0.16, 0.22, 0.25, 0.30, 0.35, 0.35, 0.39, 0.43, 0.46, 0.52, 0.56, 0.61, 0.61, 0.61, 0.67,
            0.67, 0.67, 0.67, 1.00, 1.00, 1.00,
        ])

        true_km_var = np.array([
            0., 0.00040286, 0.00235395, 0.00647525, 0.01176936,
            0.01445593, 0.01950406, 0.02558274, 0.02558274, 0.03101638,
            0.0372507, 0.04107543, 0.05064256, 0.05701375, 0.06455742,
            0.06455742, 0.06455742, 0.07407407, 0.07407407, 0.07407407,
            0.07407407, 0., 0., 0.
        ])

        assert_array_almost_equal(-x[::-1], true_x, 2)
        assert_array_almost_equal(y[::-1], true_y, 2)
        assert_array_almost_equal(km_var[::-1], true_km_var, 2)

    @staticmethod
    def test_right_truncated_adults(make_aids):
        event, time_enter, time_exit = make_aids('adults')

        x, y, km_var = kaplan_meier_estimator(event, -time_exit.values, -time_enter.values, with_variance=True)

        true_x = np.array([
            0.25, 0.50, 0.75, 1.00, 1.25, 1.50, 1.75, 2.00, 2.25, 2.50, 2.75, 3.00, 3.25, 3.50, 3.75,
            4.00, 4.25, 4.50, 4.75, 5.00, 5.25, 5.50, 5.75, 6.00, 6.25, 6.50, 6.75, 7, 7.25, 7.75, 8,
        ])

        true_y = np.array([
            0, 0.003, 0.004, 0.01, 0.02, 0.03, 0.05, 0.06, 0.07, 0.09, 0.11, 0.13, 0.16, 0.18, 0.20,
            0.21, 0.25, 0.29, 0.31, 0.34, 0.40, 0.49, 0.54, 0.58, 0.61, 0.64, 0.73, 0.8, 0.8, 1, 1,
        ])

        true_km_var = np.array([
            0.00000000e+00, 3.11657824e-06, 4.67936383e-06, 2.12228204e-05,
            5.56482988e-05, 1.11468708e-04, 2.44595782e-04, 3.52306201e-04,
            5.00296622e-04, 8.15887017e-04, 1.13615339e-03, 1.52452707e-03,
            2.37605916e-03, 3.08966117e-03, 3.67175315e-03, 4.16480108e-03,
            5.59750171e-03, 7.12460309e-03, 8.42996960e-03, 9.90350542e-03,
            1.30614489e-02, 1.82572569e-02, 2.18013609e-02, 2.42785444e-02,
            2.56244674e-02, 2.73822338e-02, 3.09629630e-02, 3.20000000e-02,
            3.20000000e-02, 0.00000000e+00, 0.00000000e+00
        ])
        assert_array_almost_equal(-x[::-1], true_x, 2)
        assert_array_almost_equal(y[::-1], true_y, 2)
        assert_array_almost_equal(km_var[::-1], true_km_var, 2)

    @staticmethod
    def test_censoring_distribution():
        y = Surv.from_arrays(
            np.array([1, 0, 0, 1, 0, 1, 0, 1, 1, 0], dtype=bool),
            np.array([1, 2, 3, 3, 3, 4, 5, 5, 6, 7]),
        )

        cens = CensoringDistributionEstimator().fit(y)

        probs = cens.predict_proba(np.arange(1, 8))
        expected = np.array([1.0, 0.8888889, 0.6349206, 0.6349206, 0.4232804, 0.4232804, 0.0000000])

        assert_array_almost_equal(expected, probs)

    @staticmethod
    def test_truncated_reverse_error(truncated_failure_data):
        with pytest.raises(
            ValueError,
            match="The censoring distribution cannot be estimated from left truncated data",
        ):
            kaplan_meier_estimator(*truncated_failure_data, reverse=True)


class TestNelsonAalen:

    @staticmethod
    @pytest.mark.parametrize("time,event,true_x,true_y", SimpleDataNACases().get_cases())
    def test_simple(time, event, true_x, true_y):
        x, y = nelson_aalen_estimator(event, time)

        assert_array_equal(x, true_x)
        assert_array_almost_equal(y, true_y)

    @staticmethod
    def test_whas500(make_whas500, whas500_true_x):
        whas500 = make_whas500(with_mean=False, with_std=False)
        time = whas500.y['lenfol']
        event = whas500.y['fstat']

        x, y = nelson_aalen_estimator(event, time)

        assert_array_equal(x.astype(int), whas500_true_x)

        true_y = np.array([
            0.016, 0.032260162601626, 0.038458509709064, 0.0426165138670682, 0.0467918792115359, 0.0572740595050369,
            0.0699859239118166, 0.0764236921521598, 0.0850630010074515, 0.089420299482397, 0.0916084832898368,
            0.0959944482021175, 0.102602377717536, 0.109254262418201, 0.113718548132487, 0.118202853065222,
            0.120455105317475, 0.12271244166059, 0.127237328538418, 0.1340555103566, 0.13634383987605,
            0.138637417857702, 0.140936268432414, 0.143240415897852, 0.145549884720023, 0.147864699534838,
            0.150184885149687, 0.152510466545036, 0.157172471207041, 0.159514391581748, 0.161861809422123,
            0.164214750598594, 0.16893173173067, 0.173671068223561, 0.176052020604513, 0.178438655449382,
            0.180830999946989, 0.183229081481762, 0.185632927635608, 0.188042566189824, 0.190458025127023,
            0.192879332633076, 0.195306517099095, 0.197739607123426, 0.20017863151367, 0.202623619288731,
            0.205074599680888, 0.20753160213789, 0.209994656325083, 0.212463792127552, 0.214939039652304,
            0.217420429230468, 0.219907991419523, 0.222401757005558, 0.224901757005558, 0.229914288333878,
            0.232433180021536, 0.234958432546788, 0.237490078116409, 0.240028149182399, 0.242572678444485,
            0.247674719260812, 0.252802924389017, 0.255380243976646, 0.257964223304811, 0.26055489687994,
            0.263152299477343, 0.26575646614401, 0.268367432201451, 0.273603034295692, 0.27623461324306,
            0.278873135670501, 0.281518638316003, 0.284171158209903, 0.286830732677988, 0.292164066011321,
            0.294845031158774, 0.297533203201785, 0.300228620991542, 0.302931323694245, 0.305641350794516,
            0.308358742098864, 0.311083537739191, 0.313815778176349, 0.319295230231144, 0.322050051167783,
            0.322050051167783, 0.322050051167783, 0.322050051167783, 0.322050051167783, 0.324866952576234,
            0.327691811333296, 0.327691811333296, 0.327691811333296, 0.330548954190439, 0.333414283703333,
            0.333414283703333, 0.333414283703333, 0.333414283703333, 0.333414283703333, 0.33633826031152,
            0.339270811631168, 0.339270811631168, 0.339270811631168, 0.339270811631168, 0.339270811631168,
            0.339270811631168, 0.339270811631168, 0.342273814634171, 0.342273814634171, 0.345294962670425,
            0.345294962670425, 0.345294962670425, 0.345294962670425, 0.345294962670425, 0.345294962670425,
            0.345294962670425, 0.348390937902623, 0.348390937902623, 0.351545512035115, 0.351545512035115,
            0.351545512035115, 0.351545512035115, 0.351545512035115, 0.351545512035115, 0.351545512035115,
            0.351545512035115, 0.354824200559705, 0.354824200559705, 0.358124530592708, 0.361435788870854,
            0.361435788870854, 0.361435788870854, 0.364780270476205, 0.364780270476205, 0.364780270476205,
            0.368158648854584, 0.368158648854584, 0.368158648854584, 0.368158648854584, 0.368158648854584,
            0.368158648854584, 0.368158648854584, 0.368158648854584, 0.368158648854584, 0.368158648854584,
            0.368158648854584, 0.368158648854584, 0.371717367715794, 0.371717367715794, 0.375314490017952,
            0.378937678423749, 0.382574042060113, 0.382574042060113, 0.382574042060113, 0.382574042060113,
            0.386305385343695, 0.386305385343695, 0.390064783839935, 0.393838368745596, 0.393838368745596,
            0.393838368745596, 0.393838368745596, 0.393838368745596, 0.393838368745596, 0.393838368745596,
            0.393838368745596, 0.393838368745596, 0.397775376619611, 0.401727945789572, 0.401727945789572,
            0.401727945789572, 0.405727945789572, 0.4097440100466, 0.413776268111116, 0.417824851107068,
            0.421889891757474, 0.421889891757474, 0.421889891757474, 0.426005118094923, 0.430137349499881,
            0.430137349499881, 0.434304016166548, 0.438488116584958, 0.442689797257227, 0.442689797257227,
            0.44692708539282, 0.451182404541756, 0.45545590881526, 0.459747754308823, 0.464058099136409,
            0.468387103465413, 0.47273492955237, 0.477101741779444, 0.481487706691725, 0.485892993035337,
            0.490317771796399, 0.490317771796399, 0.490317771796399, 0.490317771796399, 0.490317771796399,
            0.490317771796399, 0.490317771796399, 0.490317771796399, 0.490317771796399, 0.490317771796399,
            0.490317771796399, 0.490317771796399, 0.490317771796399, 0.490317771796399, 0.490317771796399,
            0.495125464104092, 0.495125464104092, 0.495125464104092, 0.495125464104092, 0.500075959153596,
            0.500075959153596, 0.505075959153596, 0.505075959153596, 0.505075959153596, 0.505075959153596,
            0.505075959153596, 0.510204164281801, 0.510204164281801, 0.510204164281801, 0.515412497615135,
            0.515412497615135, 0.515412497615135, 0.515412497615135, 0.515412497615135, 0.515412497615135,
            0.515412497615135, 0.515412497615135, 0.515412497615135, 0.520937359493588, 0.520937359493588,
            0.520937359493588, 0.520937359493588, 0.526587077007712, 0.526587077007712, 0.526587077007712,
            0.526587077007712, 0.532367423828521, 0.538249776769698, 0.538249776769698, 0.538249776769698,
            0.538249776769698, 0.538249776769698, 0.538249776769698, 0.538249776769698, 0.538249776769698,
            0.538249776769698, 0.538249776769698, 0.538249776769698, 0.538249776769698, 0.538249776769698,
            0.538249776769698, 0.538249776769698, 0.538249776769698, 0.538249776769698, 0.544872293325989,
            0.544872293325989, 0.544872293325989, 0.544872293325989, 0.544872293325989, 0.544872293325989,
            0.544872293325989, 0.544872293325989, 0.551914546847116, 0.551914546847116, 0.551914546847116,
            0.551914546847116, 0.551914546847116, 0.551914546847116, 0.551914546847116, 0.551914546847116,
            0.551914546847116, 0.551914546847116, 0.551914546847116, 0.551914546847116, 0.559788562595148,
            0.559788562595148, 0.559788562595148, 0.559788562595148, 0.559788562595148, 0.576182005218098,
            0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098,
            0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098,
            0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098,
            0.576182005218098, 0.576182005218098, 0.576182005218098, 0.576182005218098, 0.586182005218098,
            0.596283015319109, 0.606487096951762, 0.616796375302277, 0.627213041968944, 0.637739357758417,
            0.648377655630758, 0.659130343802801, 0.669999909020192, 0.680988920009203, 0.692100031120314,
            0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494,
            0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494,
            0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494,
            0.703335986176494, 0.703335986176494, 0.703335986176494, 0.703335986176494, 0.718261359310822,
            0.718261359310822, 0.718261359310822, 0.718261359310822, 0.718261359310822, 0.718261359310822,
            0.718261359310822, 0.718261359310822, 0.718261359310822, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945, 0.735805218959945,
            0.735805218959945, 0.735805218959945, 0.819138552293278, 0.819138552293278, 0.819138552293278,
            0.819138552293278, 0.819138552293278, 0.819138552293278, 0.819138552293278, 0.819138552293278,
            0.819138552293278, 1.15247188562661, 1.65247188562661, 2.65247188562661,
        ])

        assert_array_almost_equal(y, true_y)
